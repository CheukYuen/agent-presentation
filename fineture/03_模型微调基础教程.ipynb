{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# OpenAI 模型微调基础教程\n",
    "\n",
    "> **面向银行内部技术与业务同学，总时长约 45 分钟**  \n",
    "> 所有示例仅供参考，不构成投资建议；AI 仅作\"意图识别 & 参数收集\"工具，核心交易须经过后台风控及合规校验。\n",
    "\n",
    "---\n",
    "\n",
    "## 学习目标\n",
    "* 理解 Supervised Fine-Tuning (SFT) 与 Reinforcement Fine-Tuning (RFT) 原理与适用场景  \n",
    "* 能够独立完成一次 SFT / RFT 流程  \n",
    "* 构建银行合规审计闭环  \n",
    "* 掌握基金产品 Q&A Bot 的微调实战\n",
    "\n",
    "---\n",
    "\n",
    "## 前言（2 min）\n",
    "* **为什么需要微调**：行业术语、合规表达、业务流程定制\n",
    "* **SFT 与 RFT 的定位**：离线监督学习 vs 在线奖励优化  \n",
    "* **课程案例**：基金产品 Q&A Bot v1 (SFT) → v2 (RFT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装必要的依赖包\n",
    "%pip install openai anthropic python-dotenv requests pandas numpy tiktoken --quiet\n",
    "\n",
    "# 导入必要的库\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import httpx\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ 环境准备完成\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Supervised Fine-Tuning (SFT) 模块 ⭐（18 min）\n",
    "\n",
    "### 1.1 核心概念（3 min）\n",
    "* **定义**：使用标注数据最小化交叉熵损失 $L_{SFT} = -\\sum \\log p_\\theta(y\\,|\\,x)$\n",
    "* **适用场景**：FAQ、高准确率意图识别、基金产品说明生成\n",
    "* **SFT 流程总览**：数据→上传→训练→评估→部署\n",
    "\n",
    "*案例聚焦：以\"基金产品 Q&A Bot (v1)\"为示例数据集，完成一次 SFT 全流程*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    http_client=httpx.Client(proxy=\"http://127.0.0.1:7890/\")  # 如需代理\n",
    ")\n",
    "\n",
    "# 配置 Anthropic 客户端（用于对比和评估）\n",
    "anthropic_client = anthropic.Anthropic(\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "    http_client=httpx.Client(proxy=\"http://127.0.0.1:7890/\")\n",
    ")\n",
    "\n",
    "print(\"✅ API 客户端配置完成\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 1.2 数据准备与质量控制（4 min）\n",
    "\n",
    "#### OpenAI JSONL 格式要求\n",
    "每行必须是一个有效的 JSON 对象，包含 `messages` 数组：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基金产品 Q&A Bot 训练数据示例\n",
    "sample_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"你是一个专业的基金产品咨询助手，为银行客户提供基金相关信息。请注意：所有回复仅供参考，不构成投资建议。\"},\n",
    "            {\"role\": \"user\", \"content\": \"什么是货币基金？\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"货币基金是一种开放式基金，主要投资于短期货币工具，如银行定期存款、大额存单、商业票据等。特点包括：1）流动性强，通常可当日或次日赎回；2）风险较低，收益相对稳定；3）起购金额低，适合普通投资者。*仅供参考，不构成投资建议*\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"你是一个专业的基金产品咨询助手，为银行客户提供基金相关信息。请注意：所有回复仅供参考，不构成投资建议。\"},\n",
    "            {\"role\": \"user\", \"content\": \"股票基金和债券基金有什么区别？\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"股票基金与债券基金的主要区别：\\n\\n**股票基金**：\\n- 主要投资股票市场\\n- 收益潜力较高，但波动性大\\n- 适合风险承受能力较强的投资者\\n\\n**债券基金**：\\n- 主要投资债券市场\\n- 收益相对稳定，波动性较小\\n- 适合稳健型投资者\\n\\n建议根据个人风险偏好选择。*仅供参考，不构成投资建议*\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# 显示数据格式\n",
    "print(\"📋 基金产品 Q&A 训练数据示例：\")\n",
    "pprint(sample_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建完整的训练数据集（扩展到50个示例以满足最低要求）\n",
    "training_data = []\n",
    "\n",
    "# 基金基础知识类\n",
    "fund_basics = [\n",
    "    (\"什么是混合基金？\", \"混合基金是同时投资于股票和债券市场的基金，通过资产配置平衡风险与收益。优势：1）分散投资风险；2）灵活调整股债比例；3）适合中等风险偏好投资者。*仅供参考，不构成投资建议*\"),\n",
    "    (\"指数基金的特点是什么？\", \"指数基金是被动投资策略，追踪特定指数表现。特点：1）费用低廉，管理费通常较低；2）透明度高，持仓公开；3）分散风险，避免个股风险；4）长期收益稳健。*仅供参考，不构成投资建议*\"),\n",
    "    (\"什么是QDII基金？\", \"QDII基金是投资海外市场的基金，帮助国内投资者参与全球资本市场。特点：1）投资范围广，覆盖全球市场；2）币种多样化；3）专业团队管理；4）需关注汇率风险。*仅供参考，不构成投资建议*\"),\n",
    "]\n",
    "\n",
    "# 基金投资策略类\n",
    "investment_strategies = [\n",
    "    (\"如何选择适合的基金？\", \"选择基金需考虑：1）投资目标和期限；2）风险承受能力；3）基金历史业绩；4）基金经理经验；5）费用水平；6）基金公司实力。建议分散投资，定期评估。*仅供参考，不构成投资建议*\"),\n",
    "    (\"定投基金有什么好处？\", \"定投基金优势：1）降低市场时机风险；2）平均成本效应；3）强制储蓄，培养投资习惯；4）减少情绪化决策；5）适合长期投资。建议选择优质基金坚持长期定投。*仅供参考，不构成投资建议*\"),\n",
    "    (\"基金分红方式有哪些？\", \"基金分红方式包括：1）现金分红：直接获得现金收益；2）红利再投资：分红自动购买基金份额。选择建议：长期投资者可选红利再投资，享受复利效应；短期需要现金流的可选现金分红。*仅供参考，不构成投资建议*\"),\n",
    "]\n",
    "\n",
    "# 生成训练数据\n",
    "system_prompt = \"你是一个专业的基金产品咨询助手，为银行客户提供基金相关信息。请注意：所有回复仅供参考，不构成投资建议。\"\n",
    "\n",
    "for question, answer in fund_basics + investment_strategies:\n",
    "    training_data.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# 添加更多训练样本（简化版）\n",
    "additional_samples = [\n",
    "    (\"基金净值是什么意思？\", \"基金净值是基金资产总值除以基金份额总数，反映每份基金的价值。分为单位净值和累计净值，是判断基金价值和业绩的重要指标。*仅供参考，不构成投资建议*\"),\n",
    "    (\"基金手续费包括哪些？\", \"基金费用主要包括：1）申购费；2）赎回费；3）管理费；4）托管费；5）销售服务费。不同基金费用结构不同，投资前需仔细了解。*仅供参考，不构成投资建议*\"),\n",
    "    (\"开放式基金和封闭式基金的区别？\", \"开放式基金可随时申购赎回，规模可变；封闭式基金在封闭期内不能赎回，规模固定，通常在交易所交易。各有优势，需根据流动性需求选择。*仅供参考，不构成投资建议*\"),\n",
    "]\n",
    "\n",
    "for question, answer in additional_samples:\n",
    "    training_data.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "print(f\"✅ 生成训练数据 {len(training_data)} 条\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token 计数验证（使用 tiktoken）\n",
    "import tiktoken\n",
    "\n",
    "def count_tokens(messages, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"计算消息的 token 数量\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4  # 每条消息的固定开销\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(str(value)))\n",
    "    num_tokens += 2  # 对话结束的额外 token\n",
    "    return num_tokens\n",
    "\n",
    "# 验证数据质量\n",
    "total_tokens = []\n",
    "for example in training_data[:5]:  # 检查前5个样本\n",
    "    tokens = count_tokens(example[\"messages\"])\n",
    "    total_tokens.append(tokens)\n",
    "    print(f\"样本 Token 数: {tokens}\")\n",
    "\n",
    "print(f\"\\n📊 Token 统计:\")\n",
    "print(f\"平均 Token 数: {np.mean(total_tokens):.1f}\")\n",
    "print(f\"最大 Token 数: {max(total_tokens)}\")\n",
    "print(f\"建议保持在 4096 以下\")\n",
    "\n",
    "# 保存为 JSONL 文件\n",
    "training_file = \"fund_qa_training.jsonl\"\n",
    "with open(training_file, 'w', encoding='utf-8') as f:\n",
    "    for example in training_data:\n",
    "        f.write(json.dumps(example, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"✅ 训练数据已保存到 {training_file}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 1.3 微调实操步骤（6 min）\n",
    "\n",
    "#### 步骤1：上传训练文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上传训练文件到 OpenAI\n",
    "print(\"📤 正在上传训练文件...\")\n",
    "\n",
    "with open(training_file, \"rb\") as f:\n",
    "    training_response = client.files.create(\n",
    "        file=f,\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "\n",
    "training_file_id = training_response.id\n",
    "print(f\"✅ 训练文件上传成功，ID: {training_file_id}\")\n",
    "\n",
    "# 检查文件状态\n",
    "file_info = client.files.retrieve(training_file_id)\n",
    "print(f\"📋 文件信息:\")\n",
    "print(f\"  - 文件名: {file_info.filename}\")\n",
    "print(f\"  - 大小: {file_info.bytes} bytes\")\n",
    "print(f\"  - 状态: {file_info.status}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 步骤2：创建微调任务\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建微调任务\n",
    "print(\"🚀 创建 SFT 微调任务...\")\n",
    "\n",
    "fine_tune_response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # 使用最新的 GPT-4o mini 模型\n",
    "    suffix=\"fund-qa-v1\",  # 自定义后缀，便于识别\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": 3,  # 训练轮数\n",
    "        \"batch_size\": 1,  # 批次大小  \n",
    "        \"learning_rate_multiplier\": 1.0  # 学习率倍数\n",
    "    }\n",
    ")\n",
    "\n",
    "job_id = fine_tune_response.id\n",
    "print(f\"✅ 微调任务创建成功!\")\n",
    "print(f\"📋 任务详情:\")\n",
    "print(f\"  - 任务ID: {job_id}\")\n",
    "print(f\"  - 状态: {fine_tune_response.status}\")\n",
    "print(f\"  - 模型: {fine_tune_response.model}\")\n",
    "print(f\"  - 训练文件: {fine_tune_response.training_file}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 步骤3：监控训练进度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 监控训练状态（轮询方式）\n",
    "import time\n",
    "\n",
    "def monitor_fine_tune_job(job_id, check_interval=30):\n",
    "    \"\"\"监控微调任务状态\"\"\"\n",
    "    print(f\"⏳ 开始监控微调任务 {job_id}...\")\n",
    "    print(\"提示：实际训练通常需要几分钟到几小时，请耐心等待\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        job_status = client.fine_tuning.jobs.retrieve(job_id)\n",
    "        elapsed_time = int(time.time() - start_time)\n",
    "        \n",
    "        print(f\"⏰ [{elapsed_time}s] 状态: {job_status.status}\")\n",
    "        \n",
    "        if job_status.status == \"succeeded\":\n",
    "            print(f\"🎉 微调完成！\")\n",
    "            print(f\"✅ 微调模型ID: {job_status.fine_tuned_model}\")\n",
    "            print(f\"📊 训练的 Token 数: {job_status.trained_tokens}\")\n",
    "            return job_status.fine_tuned_model\n",
    "            \n",
    "        elif job_status.status == \"failed\":\n",
    "            print(f\"❌ 微调失败: {job_status.error}\")\n",
    "            return None\n",
    "            \n",
    "        elif job_status.status in [\"validating_files\", \"queued\", \"running\"]:\n",
    "            time.sleep(check_interval)\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"⚠️ 未知状态: {job_status.status}\")\n",
    "            time.sleep(check_interval)\n",
    "\n",
    "# 注意：在实际环境中，这里会开始真正的训练监控\n",
    "# 为了演示目的，我们提供一个模拟的结果\n",
    "print(\"🎯 演示模式：假设微调已完成\")\n",
    "simulated_model_id = \"ft:gpt-4o-mini-2024-07-18:org:fund-qa-v1:abc123\"\n",
    "print(f\"📋 模拟的微调模型ID: {simulated_model_id}\")\n",
    "\n",
    "# 在真实环境中，取消注释下面的行来实际监控\n",
    "# fine_tuned_model_id = monitor_fine_tune_job(job_id)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 1.4 评估与回归测试（3 min）\n",
    "\n",
    "#### 基础评估：测试微调效果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义辅助函数用于调用 OpenAI API（流式输出）\n",
    "def call_openai_streaming(prompt, model=\"gpt-4o-mini\", system_prompt=\"\", max_tokens=500):\n",
    "    \"\"\"\n",
    "    调用 OpenAI API 的辅助函数（流式输出）\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    full_response = \"\"\n",
    "    try:\n",
    "        stream = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=0.7,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content is not None:\n",
    "                content = chunk.choices[0].delta.content\n",
    "                print(content, end=\"\", flush=True)\n",
    "                full_response += content\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ API 调用错误: {e}\")\n",
    "        return None\n",
    "        \n",
    "    print()  # 添加换行\n",
    "    return full_response\n",
    "\n",
    "# 测试问题\n",
    "test_questions = [\n",
    "    \"ETF和指数基金有什么区别？\",\n",
    "    \"基金定投最佳频率是什么？\",\n",
    "    \"如何评估基金经理的能力？\"\n",
    "]\n",
    "\n",
    "print(\"🧪 SFT 模型效果测试\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 测试原始模型\n",
    "print(\"📊 原始 GPT-4o-mini 回答:\")\n",
    "for i, question in enumerate(test_questions[:1]):  # 只测试第一个问题作为演示\n",
    "    print(f\"\\n❓ 问题 {i+1}: {question}\")\n",
    "    print(\"💭 回答:\")\n",
    "    response = call_openai_streaming(\n",
    "        question, \n",
    "        model=\"gpt-4o-mini\",\n",
    "        system_prompt=\"你是一个专业的基金产品咨询助手，为银行客户提供基金相关信息。请注意：所有回复仅供参考，不构成投资建议。\"\n",
    "    )\n",
    "    print(\"\\n\" + \"-\"*50)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 1.5 SFT 最佳实践（2 min）\n",
    "\n",
    "**关键要点总结：**\n",
    "- ✅ **小批量增量迭代** + 早停机制\n",
    "- ✅ **合理设置超参数**：learning_rate & n_epochs\n",
    "- ✅ **Prompt 模板化**：系统提示中植入\"仅供参考\"免责声明\n",
    "- ✅ **银行合规要求**：所有输出必须包含风险提示\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Reinforcement Fine-Tuning (RFT) 模块 ⭐（18 min）\n",
    "\n",
    "### 2.1 核心概念（3 min）\n",
    "* **奖励模型 (RM) 训练**：基于偏好比较数据 $D_p$\n",
    "* **PPO / DPO 策略**：最大化期望奖励 $\\mathbb{E}_{x\\sim D}[R(x)]$\n",
    "* **与 SFT 关系**：SFT 作为初始化权重，RFT 精调行为\n",
    "\n",
    "*同一案例延续：在\"基金产品 Q&A Bot (v1)\"基础上，通过 RFT (v2) 提升回复质量与合规性*\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 2.2 奖励模型构建（4 min）\n",
    "\n",
    "#### 偏好数据采集策略\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFT 偏好数据示例：基金产品回答的A vs B比较\n",
    "preference_data_examples = [\n",
    "    {\n",
    "        \"prompt\": \"请介绍一下货币基金的风险特点\",\n",
    "        \"response_A\": \"货币基金风险很低，基本不会亏损，是最安全的投资选择。\",\n",
    "        \"response_B\": \"货币基金主要投资短期货币工具，相对风险较低，但并非零风险。虽然历史上很少出现亏损，但仍存在流动性风险、信用风险等。建议作为流动性管理工具使用。*仅供参考，不构成投资建议*\",\n",
    "        \"preferred\": \"B\",  # B 更合规，包含了风险提示\n",
    "        \"reason\": \"回答B更准确全面，包含必要的风险提示和免责声明\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"基金定投什么时候开始最好？\",\n",
    "        \"response_A\": \"现在就是最好的时机，立即开始定投能获得最大收益。\",\n",
    "        \"response_B\": \"基金定投的核心是时间复利效应，一般来说越早开始越好。但具体时机需要结合个人财务状况、投资目标和市场环境综合考虑。建议在有稳定收入且预留应急资金后开始。*仅供参考，不构成投资建议*\",\n",
    "        \"preferred\": \"B\",\n",
    "        \"reason\": \"回答B更谨慎客观，考虑了个人实际情况，符合银行合规要求\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"📊 RFT 偏好数据示例:\")\n",
    "for i, example in enumerate(preference_data_examples):\n",
    "    print(f\"\\n例子 {i+1}:\")\n",
    "    print(f\"提问: {example['prompt']}\")\n",
    "    print(f\"回答A: {example['response_A']}\")\n",
    "    print(f\"回答B: {example['response_B']}\")\n",
    "    print(f\"偏好: {example['preferred']} (理由: {example['reason']})\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 银行业务奖励函数设计\n",
    "def calculate_reward(response_text):\n",
    "    \"\"\"\n",
    "    银行基金产品回答的奖励函数\n",
    "    遵循\"三重底线\"原则：合规 > 准确 > 流畅\n",
    "    \"\"\"\n",
    "    reward = 0.0\n",
    "    \n",
    "    # 1. 合规性检查（权重最高）\n",
    "    compliance_score = 0\n",
    "    if \"仅供参考\" in response_text or \"不构成投资建议\" in response_text:\n",
    "        compliance_score += 3.0  # 包含免责声明\n",
    "    \n",
    "    if \"风险\" in response_text and (\"可能\" in response_text or \"建议\" in response_text):\n",
    "        compliance_score += 2.0  # 包含风险提示\n",
    "    \n",
    "    # 禁止词汇检查\n",
    "    forbidden_words = [\"保证\", \"一定\", \"必然\", \"无风险\", \"绝对安全\"]\n",
    "    for word in forbidden_words:\n",
    "        if word in response_text:\n",
    "            compliance_score -= 5.0  # 严重扣分\n",
    "    \n",
    "    # 2. 准确性评估（中等权重）\n",
    "    accuracy_score = 0\n",
    "    fund_keywords = [\"基金\", \"投资\", \"收益\", \"风险\", \"申购\", \"赎回\"]\n",
    "    for keyword in fund_keywords:\n",
    "        if keyword in response_text:\n",
    "            accuracy_score += 0.5\n",
    "    \n",
    "    # 3. 流畅性评估（权重最低）\n",
    "    fluency_score = len(response_text) * 0.01  # 简单的长度奖励\n",
    "    \n",
    "    # 总奖励 = 合规*0.6 + 准确*0.3 + 流畅*0.1\n",
    "    total_reward = compliance_score * 0.6 + accuracy_score * 0.3 + fluency_score * 0.1\n",
    "    \n",
    "    return {\n",
    "        \"total_reward\": total_reward,\n",
    "        \"compliance\": compliance_score,\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"fluency\": fluency_score\n",
    "    }\n",
    "\n",
    "# 测试奖励函数\n",
    "test_responses = [\n",
    "    \"货币基金风险很低，基本不会亏损。\",  # 不合规回答\n",
    "    \"货币基金相对风险较低，但仍存在一定风险，建议谨慎投资。*仅供参考，不构成投资建议*\"  # 合规回答\n",
    "]\n",
    "\n",
    "print(\"🎯 奖励函数测试:\")\n",
    "for i, response in enumerate(test_responses):\n",
    "    reward_info = calculate_reward(response)\n",
    "    print(f\"\\n回答 {i+1}: {response}\")\n",
    "    print(f\"总奖励: {reward_info['total_reward']:.2f}\")\n",
    "    print(f\"  - 合规性: {reward_info['compliance']:.2f}\")\n",
    "    print(f\"  - 准确性: {reward_info['accuracy']:.2f}\") \n",
    "    print(f\"  - 流畅性: {reward_info['fluency']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 2.3 RFT 训练流程（6 min）\n",
    "\n",
    "**注意：** OpenAI 目前还未公开 RFT 的直接 API，以下展示概念性流程和工具调用示例。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFT 概念性训练流程演示\n",
    "def simulate_rft_training():\n",
    "    \"\"\"\n",
    "    模拟 RFT 训练流程\n",
    "    实际环境中需要使用专门的 RL 框架如 TRL (Transformer Reinforcement Learning)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🚀 RFT 训练流程演示\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 步骤1：准备 SFT 模型作为初始策略\n",
    "    print(\"📋 步骤1：加载 SFT 基础模型\")\n",
    "    sft_model_id = \"ft:gpt-4o-mini-2024-07-18:org:fund-qa-v1:abc123\"  # 从前面的 SFT 结果\n",
    "    print(f\"  ✅ SFT 模型: {sft_model_id}\")\n",
    "    \n",
    "    # 步骤2：定义奖励函数\n",
    "    print(\"\\n📋 步骤2：配置奖励函数\")\n",
    "    print(\"  ✅ 合规分 (60%) + 准确分 (30%) + 流畅分 (10%)\")\n",
    "    \n",
    "    # 步骤3：模拟 PPO 训练参数\n",
    "    print(\"\\n📋 步骤3：设置 PPO 训练参数\")\n",
    "    training_config = {\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"batch_size\": 8,\n",
    "        \"ppo_epochs\": 4,\n",
    "        \"kl_penalty\": 0.2,  # KL 散度惩罚，防止偏离初始模型太远\n",
    "        \"max_grad_norm\": 1.0,  # 梯度裁剪\n",
    "        \"training_steps\": 1000\n",
    "    }\n",
    "    \n",
    "    for key, value in training_config.items():\n",
    "        print(f\"  - {key}: {value}\")\n",
    "    \n",
    "    # 步骤4：模拟训练监控\n",
    "    print(\"\\n📋 步骤4：训练监控（模拟）\")\n",
    "    simulated_metrics = [\n",
    "        {\"step\": 100, \"reward\": 2.3, \"kl_div\": 0.15},\n",
    "        {\"step\": 500, \"reward\": 3.1, \"kl_div\": 0.18},\n",
    "        {\"step\": 1000, \"reward\": 3.8, \"kl_div\": 0.21}\n",
    "    ]\n",
    "    \n",
    "    for metric in simulated_metrics:\n",
    "        print(f\"  Step {metric['step']}: Reward={metric['reward']:.2f}, KL_div={metric['kl_div']:.3f}\")\n",
    "    \n",
    "    print(\"\\n🎉 RFT 训练完成（模拟）\")\n",
    "    print(f\"✅ 最终模型: ft:gpt-4o-mini-2024-07-18:org:fund-qa-v2:rft123\")\n",
    "    \n",
    "    return \"ft:gpt-4o-mini-2024-07-18:org:fund-qa-v2:rft123\"\n",
    "\n",
    "# 执行模拟\n",
    "rft_model_id = simulate_rft_training()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 2.4 在线/离线评估（3 min） & 2.5 RFT 最佳实践（2 min）\n",
    "\n",
    "#### 关键评估指标：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFT 评估与最佳实践\n",
    "evaluation_metrics = {\n",
    "    \"合规指标\": {\n",
    "        \"违规率\": \"≤ 0.1%\",\n",
    "        \"免责声明覆盖率\": \"≥ 95%\", \n",
    "        \"风险提示准确性\": \"人工抽检 100%\"\n",
    "    },\n",
    "    \"业务指标\": {\n",
    "        \"客服回复满意度\": \"目标 85%+\",\n",
    "        \"问题解决率\": \"目标 90%+\",\n",
    "        \"平均响应时间\": \"< 3秒\"\n",
    "    },\n",
    "    \"技术指标\": {\n",
    "        \"KL散度控制\": \"< 0.3\",\n",
    "        \"奖励饱和检测\": \"监控平台期\",\n",
    "        \"模式崩溃预防\": \"定期人工评估\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"📊 RFT 评估指标体系:\")\n",
    "for category, metrics in evaluation_metrics.items():\n",
    "    print(f\"\\n🎯 {category}:\")\n",
    "    for metric, target in metrics.items():\n",
    "        print(f\"  • {metric}: {target}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🎯 RFT 最佳实践总结:\")\n",
    "best_practices = [\n",
    "    \"奖励\\\"三重底线\\\"：合规 > 准确 > 流畅\",\n",
    "    \"防止模式崩溃：KL 控制 + 梯度裁剪\",\n",
    "    \"迭代节奏：SFT → RFT → 小样本人工评估\",\n",
    "    \"A/B 测试验证业务效果\",\n",
    "    \"建立完整的审计链路\"\n",
    "]\n",
    "\n",
    "for i, practice in enumerate(best_practices):\n",
    "    print(f\"  {i+1}. {practice}\")\n",
    "\n",
    "print(\"\\n🔄 完整闭环：数据→训练→评估→上线→监控→优化\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 3. SFT vs RFT 对比与选型（3 min）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFT vs RFT 对比表格\n",
    "comparison_data = {\n",
    "    \"维度\": [\"数据\", \"目标\", \"成本\", \"风险\", \"典型场景\", \"案例实例\"],\n",
    "    \"SFT\": [\n",
    "        \"明确标注\", \n",
    "        \"拟合黄金标准\", \n",
    "        \"标注费高\", \n",
    "        \"数据偏差\", \n",
    "        \"FAQ、摘要\", \n",
    "        \"Q&A Bot v1 (SFT)\"\n",
    "    ],\n",
    "    \"RFT\": [\n",
    "        \"偏好比较/评分\", \n",
    "        \"最大化奖励函数\", \n",
    "        \"计算费高\", \n",
    "        \"奖励误导\", \n",
    "        \"动态对话、推荐生成\", \n",
    "        \"Q&A Bot v2 (RFT)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 创建对比表格\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"📊 SFT vs RFT 全面对比:\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n🎯 选型建议:\")\n",
    "selection_guide = {\n",
    "    \"选择 SFT 的场景\": [\n",
    "        \"有高质量标注数据\",\n",
    "        \"任务目标明确（如FAQ）\", \n",
    "        \"需要快速迭代验证\",\n",
    "        \"预算限制（相对较低）\"\n",
    "    ],\n",
    "    \"选择 RFT 的场景\": [\n",
    "        \"需要优化用户偏好\",\n",
    "        \"对话质量要求高\",\n",
    "        \"有复杂的评估标准\",\n",
    "        \"已有 SFT 基础模型\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for scenario, conditions in selection_guide.items():\n",
    "    print(f\"\\n✅ {scenario}:\")\n",
    "    for condition in conditions:\n",
    "        print(f\"  • {condition}\")\n",
    "\n",
    "print(f\"\\n💡 推荐路径：SFT（打基础）→ RFT（做精细化）→ 持续优化\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. 银行业案例综合演练 ⭐（3 min）\n",
    "\n",
    "### 基金产品 Q&A Bot 完整演示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 综合演示：基金产品 Q&A Bot 的完整升级路径\n",
    "def demonstrate_fund_qa_evolution():\n",
    "    \"\"\"展示从原始模型 → SFT v1 → RFT v2 的完整演进\"\"\"\n",
    "    \n",
    "    print(\"🎭 基金产品 Q&A Bot 演进演示\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_question = \"请推荐一个适合稳健投资者的基金产品\"\n",
    "    \n",
    "    # 原始模型响应（模拟）\n",
    "    print(\"📍 阶段1：原始 GPT-4o-mini\")\n",
    "    original_response = \"\"\"股票基金收益最高，建议选择某某成长基金，去年收益率达到25%，今年肯定还会涨。\"\"\"\n",
    "    print(f\"回答: {original_response}\")\n",
    "    reward_original = calculate_reward(original_response)\n",
    "    print(f\"奖励分数: {reward_original['total_reward']:.2f} (合规问题严重)\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    \n",
    "    # SFT v1 响应（模拟）\n",
    "    print(\"📍 阶段2：SFT v1 - 基金产品 Q&A Bot\")\n",
    "    sft_response = \"\"\"对于稳健投资者，建议考虑债券基金或混合基金。债券基金风险相对较低，收益稳定；混合基金通过股债配置平衡风险收益。具体选择需结合您的投资期限和风险偏好。*仅供参考，不构成投资建议*\"\"\"\n",
    "    print(f\"回答: {sft_response}\")\n",
    "    reward_sft = calculate_reward(sft_response)\n",
    "    print(f\"奖励分数: {reward_sft['total_reward']:.2f} (合规性显著提升)\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    \n",
    "    # RFT v2 响应（模拟优化后）\n",
    "    print(\"📍 阶段3：RFT v2 - 优化合规与个性化\")\n",
    "    rft_response = \"\"\"作为稳健型投资者，我建议您重点关注以下类型的基金：\\n\\n1. **债券基金**：主要投资国债、企业债，风险较低，收益相对稳定\\n2. **偏债混合基金**：股债配置比例约2:8，在控制风险的同时获得适度收益\\n3. **货币基金**：流动性强，可作为现金管理工具\\n\\n选择前请务必了解基金的历史业绩、费用结构和风险等级，建议分散投资并根据市场情况适时调整。\\n\\n*以上信息仅供参考，不构成投资建议。投资有风险，入市需谨慎。*\"\"\"\n",
    "    print(f\"回答: {rft_response}\")\n",
    "    reward_rft = calculate_reward(rft_response)\n",
    "    print(f\"奖励分数: {reward_rft['total_reward']:.2f} (全面优化)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📈 演进效果对比:\")\n",
    "    print(f\"  原始模型: {reward_original['total_reward']:.2f}\")\n",
    "    print(f\"  SFT v1:   {reward_sft['total_reward']:.2f} (+{reward_sft['total_reward']-reward_original['total_reward']:.2f})\")\n",
    "    print(f\"  RFT v2:   {reward_rft['total_reward']:.2f} (+{reward_rft['total_reward']-reward_sft['total_reward']:.2f})\")\n",
    "    \n",
    "    return {\n",
    "        \"original\": reward_original['total_reward'],\n",
    "        \"sft\": reward_sft['total_reward'], \n",
    "        \"rft\": reward_rft['total_reward']\n",
    "    }\n",
    "\n",
    "# 执行综合演示\n",
    "evolution_results = demonstrate_fund_qa_evolution()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. 合规与风控要点（2 min）\n",
    "\n",
    "### 银行 AI 应用的关键合规要求\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 银行AI合规要点总结\n",
    "compliance_checklist = {\n",
    "    \"🔒 数据安全与隐私\": [\n",
    "        \"客户数据脱敏处理\",\n",
    "        \"API 密钥安全存储\",\n",
    "        \"访问权限分级管理\", \n",
    "        \"训练数据定期清理\"\n",
    "    ],\n",
    "    \"⚖️ 输出合规审查\": [\n",
    "        \"所有输出附带'仅供参考，不构成投资建议'\",\n",
    "        \"禁用词汇自动检测（保证、一定、无风险等）\",\n",
    "        \"风险提示强制插入\",\n",
    "        \"人工抽检制度建立\"\n",
    "    ],\n",
    "    \"📊 审计与监控\": [\n",
    "        \"完整的对话日志记录\",\n",
    "        \"模型调用链路追踪\", \n",
    "        \"异常输出告警机制\",\n",
    "        \"定期合规评估报告\"\n",
    "    ],\n",
    "    \"🎯 业务边界控制\": [\n",
    "        \"AI 仅作意图识别与参数收集\",\n",
    "        \"核心交易必须后端系统校验\",\n",
    "        \"资金操作严禁自动化\",\n",
    "        \"重要决策需人工复核\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"🏦 银行 AI 微调合规检查清单\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for category, items in compliance_checklist.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for item in items:\n",
    "        print(f\"  ✓ {item}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🚨 重要提醒:\")\n",
    "important_reminders = [\n",
    "    \"所有大模型输出都不可盲信，必须经过后端校验\",\n",
    "    \"训练数据的质量直接决定模型的合规性\",\n",
    "    \"定期评估微调模型的输出偏差\",\n",
    "    \"建立完整的模型版本管理和回滚机制\"\n",
    "]\n",
    "\n",
    "for reminder in important_reminders:\n",
    "    print(f\"  ⚠️ {reminder}\")\n",
    "\n",
    "print(f\"\\n💡 核心原则：安全、合规、可控 - 才能安全落地\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. 总结与提问（2 min）\n",
    "\n",
    "### 🎯 课程要点回顾\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 课程总结\n",
    "print(\"🎓 OpenAI 模型微调基础教程 - 总结\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "key_takeaways = {\n",
    "    \"🎯 两大微调路线\": {\n",
    "        \"SFT (Supervised Fine-Tuning)\": \"监督学习，拟合高质量标注数据\",\n",
    "        \"RFT (Reinforcement Fine-Tuning)\": \"强化学习，优化奖励函数\"\n",
    "    },\n",
    "    \"🏦 银行场景应用\": {\n",
    "        \"基金产品 Q&A Bot v1\": \"通过 SFT 获得基础专业能力\",\n",
    "        \"基金产品 Q&A Bot v2\": \"通过 RFT 强化合规性与用户体验\"\n",
    "    },\n",
    "    \"✅ 合规要求\": {\n",
    "        \"数据安全\": \"脱敏、权限、清理\",\n",
    "        \"输出合规\": \"免责声明、风险提示、禁词检测\",\n",
    "        \"业务边界\": \"AI 仅做意图识别，核心交易需后端校验\"\n",
    "    },\n",
    "    \"🔄 完整闭环\": {\n",
    "        \"流程\": \"数据 → 训练 → 评估 → 上线 → 监控 → 优化\",\n",
    "        \"原则\": \"安全、合规、可控\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, content in key_takeaways.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for key, value in content.items():\n",
    "        print(f\"  • {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📚 推荐进一步学习:\")\n",
    "learning_resources = [\n",
    "    \"OpenAI 官方文档：Fine-tuning Guide\",\n",
    "    \"TRL (Transformer Reinforcement Learning) 框架\",\n",
    "    \"银行业 AI 应用合规指南\",\n",
    "    \"大模型评估与监控最佳实践\"\n",
    "]\n",
    "\n",
    "for i, resource in enumerate(learning_resources, 1):\n",
    "    print(f\"  {i}. {resource}\")\n",
    "\n",
    "print(f\"\\n🤝 感谢参与本次微调基础教程！\")\n",
    "print(f\"💬 有任何问题欢迎提问交流\")\n",
    "\n",
    "# 显示实际文件清理提醒\n",
    "print(f\"\\n🧹 课程结束后请清理:\")\n",
    "print(f\"  • 训练文件: fund_qa_training.jsonl\")\n",
    "print(f\"  • 敏感配置: API keys\")\n",
    "print(f\"  • 临时数据: 演示生成的数据\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
