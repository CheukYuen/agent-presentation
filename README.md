# AI Agent 开发与微调实战项目

## 📋 项目概述

本项目旨在通过实战演练，帮助团队掌握 Anthropic 与 OpenAI 智能体开发与微调的核心技能。项目包含完整的 Agent 架构设计、Prompt 工程实践、工具集成、MCP 服务及模型微调等关键内容。

## 📖 培训内容

### 第一章：人工智能时代的软件 (35分钟)

#### 1.1 大型语言模型特性
- **公用事业特性**：类似电力系统，按需提供智能服务（按token计费）
- **实验室特性**：需要巨大资本投入，技术快速迭代，研发高度集中
- **操作系统特性**：复杂软件生态系统，闭源与开源并存
- **类人灵魂特质**：具有人类般的推理能力但易犯错，需要学会协作

#### 1.2 设计具有部分自主性的大型语言模型应用
- **自主性滑块概念**：从完全人工控制到完全自主的连续调节
- **Agent作为新型信息使用者**：介于人类GUI操作和传统API调用之间
- **钢铁侠战衣模式**：人机深度融合，增强人类能力而非完全替代
- **为Agent构建友好基础设施**：AI友好的Markdown格式文档

#### 1.3 AI 驱动的开发工具
- **Cursor**：AI 辅助代码编辑器
- **OpenAI Deep Research**：深度研究助手
- **Google NotebookLM**：智能笔记系统
- **Anthropic Artifacts**：可执行内容生成


### 第二章：核心技能掌握 (45分钟) ⭐

- **AI Agent 基础架构** (10分钟)：理解智能体的核心组件和工作原理
- **Prompt 工程** (15分钟)：学会设计高效、可复用的提示词
- **Tools 工具集成** (10分钟)：掌握外部工具和API的集成方法
- **MCP 服务** (5分钟)：学会扩展 Agent 能力边界
- **模型微调** (5分钟)：OpenAI微调 Supervised fine-tuning (SFT) 和  Reinforcement fine-tuning (RFT)

## 📚 延伸阅读：了解大语言模型 (课后自学)

#### 预训练 (Pretraining)
- **数据与分词**：大规模文本数据处理，分词器设计原理
- **Transformer架构**：神经网络输入输出机制，内部注意力机制
- **推理过程**：模型推理的计算流程和优化策略
- **实践案例**：GPT-2训练流程，Llama 3.1基础推理示例

#### 监督微调 (Supervised Finetuning)
- **对话数据构建**：高质量对话数据集的设计与标注
- **LLM心理学特征**：
  - 幻觉现象及其产生机制
  - 工具使用能力的培养
  - 知识与工作记忆的区别
  - 模型自我认知能力
  - 思考需要token消耗的特性
  - 拼写能力与参差不齐的智能表现

#### 强化学习 (Reinforcement Learning)
- **熟能生巧原理**：通过反复练习提升模型性能
- **前沿案例分析**：
  - DeepSeek-R1：推理能力强化学习
  - AlphaGo：游戏领域的RL突破
- **RLHF方法**：人类反馈强化学习的实现机制

## 🛠️ 技术栈

### 编程语言
- **Python**：后端开发和AI集成
- **TypeScript**：前端和全栈开发

### 开发工具
- **Cursor**：AI辅助代码编辑器

### API服务
- **OpenAI API**：o4系列模型
- **Anthropic Claude API**：Claude-4系列模型

## 📚 学习资源

### 核心参考资料
- Andrej Karpathy：[《深入了解ChatGPT之类的大语言模型|Deep Dive into LLMs like ChatGPT》](https://www.youtube.com/watch?v=zjkBMFhNj_g)
- Andrej Karpathy：[《Software Is Changing》](https://www.ycombinator.com/library/MW-andrej-karpathy-software-is-changing-again)

### 官方文档
- [Anthropic Claude API](https://docs.anthropic.com/)
- [OpenAI API](https://platform.openai.com/docs)

---

**注意**：本项目文档和代码将随着学习进度持续更新，请定期查看最新版本。